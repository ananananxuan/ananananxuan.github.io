---
layout: mypost
title: 机器学习
categories: [机器学习]
extMath: true
---
# 机器学习

机器学习分为有监督学习和无监督学习

## 1.有监督学习：特征值＋目标值
分类/回归  

分类：K近邻、决策树、随机森林、支持向量机、朴素贝叶斯、逻辑回归、XGBoost、LightGBM、神经网络

回归：线性回归、岭回归、Lasso回归、ElasticNet回归、XGBoost回归、LightGBM回归、神经网络

## 2.无监督学习：特征值
聚类  

机器学习的一般步骤  
1.获取数据 sklearn自带数据集、kaggle  
2.数据处理 缺失值/不符合要求的数据  pandas
3.特征工程  

数据划分  
1.划分训练集和测试集  
2.划分特征和目标值  

4.机器学习算法训练  
5.模型评估  
6.模型调优  
7.模型部署  

## 从scikit-learn导入数据集
sklearn.datasets.load_* 小规模数据集  
sklearn.datasets.fetch_* 大规模数据集  

包括feature_names，data和target_names，target  

from sklearn.datasets import load_iris  
iris = load_iris()  

print(iris.data) X  
print(iris.target) y  
print(iris.feature_names) feature_names  
print(iris.target_names) target_names  

## 数据划分
from sklearn.model_selection import train_test_split  
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=22)

## 特征工程
特征提取
1.字典特征
将类别转化成one-hot 编码
from sklearn.feature_extraction import DictVectorizer

dv = DictVectorizer(sparse=False )
sparse = False 表示返回的值不是稀疏矩阵
sparse = True 表示返回的值是稀疏矩阵 可以节省内存

data = [{'city': '北京', 'temperature': 100}, {'city': '上海', 'temperature': 60}]   

X = dv.fit_transform(data)  

print(dv.get_feature_names())  
print(X)  


2.文本特征提取
单词作为特征,统计样本中单词个数
```
from sklearn.feature_extraction.text import CountVectorizer

transfer = CountVectorizer(stop_words=['is']) 
stop_words 停用词，可以在网上找停用词表
data = [
    "life is short, i like python",
    "life is too long, i dislike python",
    "i want to write some python code"
]

X = transfer.fit_transform(data)

print(transfer.get_feature_names())  
print(X.toarray())
```
对中文进行文本抽取
中文划词
```
import jieba

data = [
    "我爱北京天安门"
]
a = "".join(list(jieba.cut(data, cut_all=False)))
print(a)
```
划词提取关键字
```
data2 = [
    "我爱北京天安门",
    "天安门上太阳升"
]

data_new = []
for sentence in data2:
    a = " ".join(list(jieba.cut(sentence, cut_all=False)))
    data_new.append(a)

print(data_new)

from sklearn.feature_extraction.text import CountVectorizer

transfer = CountVectorizer()
X = transfer.fit_transform(data_new)

print(transfer.get_feature_names())  
print(X.toarray())
```

用TF-IDF进行文本抽取
TF term frequency 词频
IDF inverse document frequency 逆向文件频率
```
    from sklearn.feature_extraction.text import TfidfVectorizer

    transfer = TfidfVectorizer()
    X = transfer.fit_transform(data_new)

    print(transfer.get_feature_names())
```