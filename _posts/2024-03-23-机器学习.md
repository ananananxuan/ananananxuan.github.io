---
layout: mypost
title: 机器学习
categories: [机器学习]
extMath: true
---
# 机器学习

机器学习分为有监督学习和无监督学习

## 1.有监督学习：特征值＋目标值
分类/回归  

分类算法：K近邻、决策树、随机森林、支持向量机、朴素贝叶斯、逻辑回归、XGBoost、LightGBM、神经网络

回归算法：线性回归、岭回归、Lasso回归、ElasticNet回归、XGBoost回归、LightGBM回归、神经网络

## 2.无监督学习：特征值
聚类  

# 机器学习流程
机器学习的一般步骤  
1. 获取数据 sklearn自带数据集、kaggle  
2. 数据处理 缺失值/不符合要求的数据  pandas
3. 数据划分
3. 特征工程 标准化，降维（按需）
4. 机器学习算法训练  
5. 模型评估   
6. 模型部署 
 


## 获取数据（sklearn自带数据集、kaggle）
sklearn.datasets.load_* 小规模数据集    
sklearn.datasets.fetch_* 大规模数据集    

包括feature_names，data和target_names，target    
```
from sklearn.datasets import load_iris    
iris = load_iris()    

print(iris.data) X  
print(iris.target) y  
print(iris.feature_names) feature_names  
print(iris.target_names) target_names  
```

## 数据划分
数据划分  
1.划分训练集和测试集  
2.划分特征和目标值 
```
from sklearn.model_selection import train_test_split  
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=22)
```

## 特征工程
特征提取  
1.字典特征  
将类别转化成one-hot 编码

```
from sklearn.feature_extraction import DictVectorizer

dv = DictVectorizer(sparse=False )
sparse = False 表示返回的值不是稀疏矩阵
sparse = True 表示返回的值是稀疏矩阵 可以节省内存

data = [{'city': '北京', 'temperature': 100}, {'city': '上海', 'temperature': 60}]   

X = dv.fit_transform(data)  

print(dv.get_feature_names())  
print(X)  
```

2.文本特征提取    

countvectorizer统计特征词个数和tfidfvectorizer统计特征词重要性两种方法     
对英文进行文本抽取
```
from sklearn.feature_extraction.text import CountVectorizer

transfer = CountVectorizer(stop_words=['is']) 
stop_words 停用词，可以在网上找停用词表
data = [
    "life is short, i like python",
    "life is too long, i dislike python",
    "i want to write some python code"
]

X = transfer.fit_transform(data)

print(transfer.get_feature_names())  
print(X.toarray())
```

对中文进行文本抽取  
中文划词
```
import jieba

data = [
    "我爱北京天安门"
]
a = "".join(list(jieba.cut(data, cut_all=False)))
print(a)
```
划词提取关键字
```
data2 = [
    "我爱北京天安门",
    "天安门上太阳升"
]

data_new = []
for sentence in data2:
    a = " ".join(list(jieba.cut(sentence, cut_all=False)))
    data_new.append(a)

print(data_new)

from sklearn.feature_extraction.text import CountVectorizer

transfer = CountVectorizer()
X = transfer.fit_transform(data_new)

print(transfer.get_feature_names())  
print(X.toarray())
```

用TF-IDF进行文本抽取 
TF term frequency 词频  
IDF inverse document frequency 逆向文件频率  
```
    from sklearn.feature_extraction.text import TfidfVectorizer

    transfer = TfidfVectorizer()
    X = transfer.fit_transform(data_new)

    print(transfer.get_feature_names())
    print(X.toarray())
```

## 特征预处理
1.归一化  
因为每个特征的量纲不统一，所以要做归一化，映射到[0,1]之间,但是如果最大值/最小值出现异常值，容易受到影响，适合精确的小数据场景。

x1 = x-min/max-min  
x2 = x1*(mx-mi)+mi
```
from sklearn.preprocessing import MinMaxScaler

transfer = MinMaxScaler()

X = transfer.fit_transform(data)

print(X)
```

2.标准化  
对每个特征的每个样本进行标准化，适合大样本场景。  
x = x - mean/std   
转换成均值为0，方差为1的正态分布  
```
from sklearn.preprocessing import StandardScaler

transfer = StandardScaler()

X = transfer.fit_transform(data)

print(X)
```

## 特征降维
对二维数组进行降维，降低特征个数，得到一组不相关主变量的过程，减少冗余信息
**1.特征选择**    
filter 过滤式  
过滤低方差特征  
```
from sklearn.feature_selection import VarianceThreshold

transfer = VarianceThreshold(threshold=0.0)

X = transfer.fit_transform(iris.data)

print(X)
```
    
相关系数选择 (皮尔森相关系数选择)  
[-1,1] >0正相关 <0负相关  
绝对值<0.4 低相关  
绝对值>0.7 高相关  

```
from scipy.stats import pearsonr
personr(x,y)计算x和y的相关性
```
当遇到特征相关性强的  
选取其中一个特征或者加权求和  

**2.主成分分析降维**
```
from sklearn.decomposition import PCA
transfer = PCA(n_components=2) #表示降到2维，传小数表示保留信息0.95
X = transfer.fit_transform(data)
print(X)
```

embedded 嵌入式  
决策树    
正则化  
深度学习  

# sklearn和估计器
1.转换器(特征工程的父类)  
实例化，将转换器类进行实例化 transformer
调用，fit_transform方法
eg:标准化
x-mean/std
```
standardscaler = StandardScaler()
X = standardscaler.fit_transform(X)
```
fit()用于计算每一列的均值和方差
transform()用于带入x-mean/std

2.估计器(机器学习算法的父类)  
实例化，将估计器类进行实例化 estimator
调用，estimator.fit(X_train,y_train)
模型评估
直接比较预测值和真实值

y_predict = estimator.predict(X_test)
y_test == y_predict

计算准确率
accuracy = estimator.score(X_test,y_test)

# KNN算法
  根据邻居距离预测类别，需要无量纲化（标准化）

  k表示邻居的个数，k过大容易受到样本不均衡的影响，k过小容易受到异常值影响
  确认距离：
  欧式距离：
  ((x1-x2)^2+(y1-y2)^2)^(1/2)
  曼哈顿距离：
    |x1-x2|+|y1-y2|
  明科夫斯基：
    (|x1-x2|^p+|y1-y2|^p)^(1/p)

    ```
    from sklearn.neighbors import KNeighborsClassifier


