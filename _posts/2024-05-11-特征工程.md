---
layout: mypost
title: 特征工程
date: 2024-05-09 12:00:00 +0800
tags: [数据分析]
categories: [数据分析]
extMath: true
---

学习来源:
https://tianchi.aliyun.com/notebook/129447

# 特征工程的一般步骤

## 1.导库
```
import numpy as np #处理ndarray结构的数据
import pandas as pd #处理表格数据
import matplotlib.pyplot as plt #画图
import seaborn as sns #画图

from scipy import stats #从科学计算库scipy中导入stats模块,包含统计和概率描述

import warnings
warnings.filterwarnings("ignore") #不显示警告
```
## 2.读入数据
```
train_data_file = "./zhengqi_train.txt"
test_data_file = "./zhengqi_test.txt" 

train_data = pd.read_csv(train_data_file,sep="\t")
test_data = pd.read_csv(test_data_file,sep="\t")
```
## 3.初识数据
```
train_data.head()
train_data.shape #数据形状
train_data.info() #有无空值以及数据类型，可省略
train_data.describe() #看看最大最小值和均值，是否需要归一化
```

## 4.数据处理

### 4.1 异常值观察和处理
```
plt.figure(figsize=(18, 10))
plt.boxplot(x=train_data.values,labels=train_data.columns) #画箱线图观察样本的特征值分布
plt.hlines([-7.5, 7.5], 0, 40, colors='r')#[-7.5,7.5]以外的算是异常值
plt.show()
```
```
train_data = train_data[train_data['V9']>-7.5]

plt.figure(figsize=(18, 10))
plt.boxplot(x=train_data.values,labels=train_data.columns)
plt.hlines([-7.5, 7.5], 0, 40, colors='r')#[-7.5,7.5]以外的算是异常值
plt.show()
```

### 4.2 训练集和测试集数据分布情况
```
dist_cols = 6
dist_rows = 7
plt.figure(figsize=(5*dist_cols,5*dist_rows))

i = 1
for col in test_data.columns:
    ax = plt.subplot(dist_rows,dist_cols,i)
    ax = sns.kdeplot(train_data[col],color="Red",shade=True) #画数据分布图的方法
    ax = sns.kdeplot(test_data[col],color="Blue",shade=True)
    ax.set_xlabel(col) #每一次循环会换一个横坐标
    ax.set_ylabel("Frequency")
    ax = ax.legend(["train","test"])
    
    i += 1
plt.show()
# 特征'V5','V9','V11','V17','V22','V28' 训练集数据与测试集数据分布不一致，会导致模型泛化能力差，采用删除此类特征方法
```

```
X_train.drop(["V5","V9","V11","V17","V22","V28"],axis=1,inplace=True)
X_test.drop(["V5","V9","V11","V17","V22","V28"],axis=1,inplace=True)
```

### 4.3 画出每个特征之间以及特征和标签之间的相关性热图
```
data_train1 = train_data.drop(['V5','V9','V11','V17','V22','V28'],axis=1)
#把特征'V5','V9','V11','V17','V22','V28' 训练集数据与测试集数据分布不一致，将这些特征舍弃
train_corr = data_train1.corr()
plt.figure(figsize=(18,18), dpi=300) 
# 创建一个掩膜
mask = np.triu(np.ones_like(train_corr, dtype=bool))

sns.heatmap(train_corr,  mask=mask, annot=True, fmt=".2f", cmap='coolwarm')  # 画出热力图
plt.show()
```

## 5.归一化数据
对特征数据进行归一化
```
from sklearn.preprocessing import MinMaxScaler

transfer = MinMaxScaler()

X_train = data_train2.iloc[:,:-1]
y_train = pd.DataFrame(data_train2['target'])
X_test = data_test2

X_train = pd.DataFrame(transfer.fit_transform(X_train))
X_test = pd.DataFrame(transfer.transform(X_test))
```



更加详细的代码放在github中:   
https://github.com/ananananxuan/industrial-steam-program/blob/main/%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2.ipynb


## 6.降维

### 6.1 根据相关性降维
```
train_corr = train_corr.abs()
train_corr[train_corr["target"]>0.1]["target"].sort_values(ascending=False)#把和target相关性大于0.1的特征找出来
```

### 6.2 PCA降维
```
from sklearn.decomposition import PCA

pca = PCA(n_components=0.95)
X_train_pca = pd.DataFrame(pca.fit_transform(X_train))
X_test_pca = pd.DataFrame(pca.transform(X_test))

train_data2 = pd.concat([X_train_pca,y_train],axis=1)
train_data2.describe()
```






