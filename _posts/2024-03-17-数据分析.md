---
layout: mypost
title: 数据分析
categories: [数据分析]
extMath: true
---
# python数据分析

## 1.对ndarray格式的文件基本操作
ndarray是numpy库的核心数据结构，它是一个多维数组，可以存储不同类型的数据。  
ndarray是对象，有属性和方法  
**ndarray的属性：**    
a.shape  
a.dtype  
**ndarray的方法：**   
a.方法()  
np.函数名()  

### 1. 生成数组
#### 1.1 生成0和1
```
np.zeros((3,4), dtype=float )
```

#### 1.2 从现有数组中生成
```
    np.array([[1,2],[3,4]])
```
#### 1.3 生成固定范围的数组
```
    np.linspace(0,10,11)
    # 生成[0,10]等距离的11个数

    np.arange(0,10,2)
    # 生成[0,10)等距离的数，步长为2

    range(a,b,c)
    # 生成[a,b)等距离的数，步长为c
```
#### 1.4 生成随机数
```
    np.random.uniform(0,1,10000)
    # 均匀分布，生成10000个[0,1)之间10000个随机数

    np.random.normal(0,1,10000)
    # 正态分布，生成10000个均值为0，标准差为1的随机数

```
### 2. 数组操作
#### 2.1 数组的索引和切片
```
a[0,0:3] # 取第1行第1列到第2列的元素 [0,3)
a[1,0,2] # 取第二个二维数组中第1行第0列的第三个元素
```
#### 2.2 数组的转置和重塑
```
    a.T # 转置
    a.reshape(3,4) # 重塑为3行4列，有返回值
    a.resize(4,3) # 重塑为4行3列,没有返回值，直接把原始数据修改了
    a.flatten() # 变成一维数组
```
#### 2.3 数组类型的修改
```
    a.astype("int32") # 把数组类型改为int
```
#### 2.4 数组的去重
```
    np.unique(a) # 去重
```
### 3. 数组的运算
#### 3.1 逻辑运算
```
    # 统一操作符合某一条件的数据
    a>0 # 逻辑运算
    a[a>0] = 1 # 逻辑运算
    np.where(a>0,1,0) # 逻辑运算
```
#### 3.2 通用判断函数
```
    np.all(a>0) # 有一个False就返回False，全是True才返回True
    np.any(a>0) # 有一个True就返回True，全是False才返回False
```
#### 3.3 通用统计函数
```
    a.max()
    a.min()
    a.mean()
    a.std()
    axis = 0,1,2... # 统计每一列/每一行的平均值
    a.argmax() # 返回最大值的索引

```
#### 3.4 数组间运算
```
    a+b # 加法
    shape 从右到左依次排开，要么维度为一，要么相等才可以进行运算

```
#### 3.5 矩阵的运算
矩阵乘法：(m,n)×(n,l)-> (m,l) 
```
    np.dot(a,b) # 矩阵乘法
    np.matmul(a,b) # 矩阵乘法
    a @ b # 矩阵乘法
```
#### 3.6 数组的合并与分割
```
    np.concatenate((a,b),axis=0) # 往下加
    np.vstack((a,b)) # 往下加
    np.hstack((a,b)) # 往右加
    np.concatenate((a,b),axis=1) # 往右加

    np.split(a,3,axis=0) # 分割
```








## 2.对dataframe格式的文件基本操作

### 1. 数据结构
1.DataFrame是pandas库的核心数据结构，它是一个二维表格，可以存储不同类型的数据。  

2.Panel是pandas库的另一个数据结构，它是一个三维表格，可以存储不同类型的数据。

3.Series是pandas库的另一个数据结构，它是一个一维数组，可以存储不同类型的数据。

### 2.行列索引
#### 1.重新设置行列索引
```
stock = ["股票{}".format(i) for i in range(1,6)]
date = ["2019-01-0{}".format(i) for i in range(1,6)]
date = pd.date_range("2019-01-01", periods=5)

data = pd.DataFrame(np.random.rand(5,4),index=date,columns=stock)
```
#### 2.重新设置行索引
```
    data.reset_index(inplace=True)
```
#### 3.设置某一列为行索引
```
    data.set_index("列名",inplace=True)
```


### 3. DataFrame的属性
1. data.shape
2. data.index
3. data.columns
4. data.values
5. data.dtypes
6. data.T

### 4. DataFrame的方法
1. data.head(n)
2. data.tail(n)
3. data.describe()
4. data.info()













1. 创建DataFrame：df = pd.DataFrame(data)  
2. 读取数据：pd.read_csv(filename)或pd.read_excel(filename)等  
3. 查看头部数据：df.head(n)   
4. 查看形状：df.shape()    
5. 查看列名：df.columns()
6. 查看数据信息：df.info()  
7. 数据描述性统计：df.describe()   
8. 选择列：  
    -选择一列 df['column_name']或df.column_name  
    -选择多列 df[['column1', 'column2']]  
    -通过序号选择列 df.iloc[:, index]
9. 选择行：  
    -选择一行或多行 df[df['column_name'].isin([value1, value2, ...])]  
    -选择不包含某些值的行 df[~df['column_name'].isin([value1, value2, ...])]  
    -通过序号选择行 df.iloc[start_index:end_index]  
10. 根据条件选择：df[df['column']>value]
11. 缺失值处理：df.dropna()或df.fillna(value)
12. 排序： 
df.sort_values(['column1', 'column2'],ascending = [True, False])   
其中True表示升序（1，2，3……），False表示降序（3，2，1……）  
13. 分组：df.groupby('column_name')
14. 应用函数：df.apply(function)


### 1. 数据清洗
1. 数据导入： 使用正确的方法（如pandas的read_csv，read_excel等）将数据加载到Python。

2. 数据观察： 使用.head(), .tail(), .info() 等函数对数据的结构和特点进行初步了解。

3. 数据类型转换： 确保所有数据都以正确的格式（整数、浮点数、文本等）存储。例如，日期应该存储为日期类型，而不是字符串类型。可以使用pandas的.astype()方法进行转换。
time = pd.to_datetime(df['date_column'], unit='s')年月日时间
date = pd.DatetimeIndex(time_value)
date.year
date.month
date.day
date.hour
date.weekday
date.week

转换成字典：
x = x.to_dict(orient='records')
字典特征抽取：
from sklearn.feature_extraction import DictVectorizer
vec = DictVectorizer(sparse=False)
X_train = vec.fit_transform(x_train)
X_test = vec.transform(x_test)



4. 处理缺失值： 这可能包括填充缺失值，删除有缺失值的行/列，或通过一些规则（如平均值、中位数、众数、回归等）来填充缺失值。常用的函数有.isnull().any(), .notnull(), .fillna(.mean(),inplace=True), .dropna()等。

数值转换：
data.replace('-', np.nan, inplace=True)
data.dropna(inplace=True)


5. 处理重复值： 如果数据中存在重复的行，需要进行处理，可以选择删除重复行或者根据业务需求处理重复值。这可以用.duplicated()和.drop_duplicates()实现。

6. 数据规范化： 对于一些连续的数值特征，可能会需要将其转化为标准格式，如将数值标准化至0-1范围，或转化为均值为0、标准差为1的分布。这可以用到的库包括sklearn的StandardScaler与MinMaxScaler等。

7. 异常值处理： 根据业务场景，剔除明显偏离正常范围的数据值，如IQR方法等。
缩小数据范围：data.query('column_name > 0')
低频数据过滤：data.groupby('column_name').count()>3
data[列名].isin(data.groupby('column_name').count()>3.index.values)

8. 特征工程： 依据实际情况选择合适的方法对历史数据进行特征提取和构造，这可以提升数据分析或机器学习模型的性能。对于类别特征，可能会进行One-hot编码等。

9. 数据验证： 在清洗完数据后，需要回头检查数据是否符合我们的预期，以便及时发现可能的错误。

## 2. 数据预处理


## 4. 数据挖掘

## 5. 数据建模

## 6. 数据预测

## 7. 数据报告

## 8. 数据分析工具